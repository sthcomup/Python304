缓存

==scrapy -->  8/10==

Git SVA

Mysql和nosql的区别

##### 



##### queue

​	PriorityQueue（）--> !!!

​	Queue(FIFO)

​	LifoQueue()

## Django、 Flask、Tornado框架的比较？

**Django 、Flask、Tornado的对比**

```python
1.'Django'走的是大而全的方向,开发效率高。它的MTV框架,自带的ORM,admin后台管理,自带的sqlite数据
库和开发测试用的服务器
给开发者提高了超高的开发效率
2.'Flask'是轻量级的框架,自由,灵活,可扩展性很强,核心基于Werkzeug WSGI工具和jinja2模板引擎
3.'Tornado'走的是少而精的方向,性能优越。它最出名的是异步非阻塞的设计方式
Tornado的两大核心模块：
#    1.iostraem：对非阻塞式的socket进行简单的封装
#    2.ioloop：对I/O多路复用的封装，它实现了一个单例
```

Flask :

>  flask，微型框架，内部组件就比较少了，但是有很多第三方组件来扩展它，比如说有那个wtform（与django的modelform类似，表单验证）、flask-sqlalchemy（操作数据库的）、flask-session、flask-migrate、flask-script、blinker可扩展强，第三方组件丰富。所以对他本身来说有那种短小精悍的感觉

Tornado:

>  是一个轻量级的Web框架，异步非阻塞+内置WebSocket功能。
>
>  '目标'：通过一个线程处理N个并发请求(处理IO)。
>
> 内部组件：
>   a.内部自己实现socket
>   b.路由系统
>   c.视图
>   d.模板
>   e.cookie
>   f.csrf

##### **共同点：** 

` Django和Flask的共同点就是，他们2个框架都没有写socket，所以他们都是利用第三方模块wsgi;而Tornado自带socket组件。 `  

##### **不同点：** 

> 但是内部使用的wsgi也是有些不同的：Django本身运行起来使用wsgiref，而Flask使用werkzeug wsgi，还有一个区别就是他们的请求管理不太一样：django是通过将请求封装成==request对象==，再通过参数传递，而flask是通过==上下文管理机制== 

####  Django请求的生命周期？

>  用户请求进来先走到 ` wsgi,然后将请求交给 Django的中间件,穿过中间件`（方法是process_request）,接着就是路由匹配,路由匹配成功之后就执行相应的视图函数,在视图函数中可以==调用orm做数据库操作==,再从模板路径将模板拿到,然后在后台进行模板渲染,模板渲染完成之后就变成一个字符串,再把这个字符串经过所有中间件（方法：process_response）和wsgi 返回给用户

```python 
#1.wsgi,请求封装后交给web框架 （Flask、Django）     
#2.中间件，对请求进行校验或在请求对象中添加其他相关数据，例如：csrf、request.session - 
#3.路由匹配 根据浏览器发送的不同url去匹配不同的视图函数    
#4.视图函数，在视图函数中进行业务逻辑的处理，可能涉及到：orm、templates => 渲染 - 
#5.中间件，对响应的数据进行处理。 
#6.wsgi,将响应的内容发送给浏览器。
```

<img src="https://img2018.cnblogs.com/blog/1165731/201810/1165731-20181004144648932-305961052.png" alt="img" style="zoom: 50%;" />

------------------------------------------------
####  **CSRF（跨站点请求伪造）:** 

- 目前防御 CSRF 攻击主要有三种策略：
  - 1).验证 HTTP Referer 字段；
  - 2).在请求地址中添加 token 并验证；
  - 3).在 HTTP 头中自定义属性并验证 

### Django orm 中如何设置读写分离

方式一：手动使用queryset的using方法

方式二：写配置文件



### 基于Django使用ajax发送post请求时，都可以使用哪种方法携带csrf token？

>  方式一：给每个ajax都加上请求头

> 方式二：需要先下载jQuery-cookie，才能去cookie中获取token

>  方式三：搞个函数ajaxSetup，当有多的ajax请求，即会执行这个函数

###  **REST与RPC概念** 

 **什么是REST** 

>  REST是一种架构风格，指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是==RESTful== 。REST规范把所有内容都视为资源，网络上一切皆资源。 

 **什么是RPC** 

>  远程方法调用，就是像调用本地方法一样调用远程方法。常见RPC框架结构图： 

![img](https://ss0.baidu.com/6ONWsjip0QIZ8tyhnq/it/u=1796673822,345432463&fm=173&app=49&f=JPEG?w=640&h=384&s=D800DF141BF6448A137188C8030080B1)

 **RPC框架要做到的最基本的三件事： ** 

 1、服务端如何确定客户端要调用的函数； 

>  在远程调用中，客户端和服务端分别维护一个【ID->函数】的对应表， ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，附上这个ID，服务端通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 

 2、如何进行序列化和反序列化； 

>  客户端和服务端交互时将参数或结果转化为字节流在网络中传输，那么数据转化为字节流的或者将字节流转换成能读取的固定格式时就需要进行序列化和反序列化，序列化和反序列化的速度也会影响远程调用的效率 

 3、如何进行网络传输（选择何种网络协议）；

>   多数RPC框架选择TCP作为传输协议，也有部分选择HTTP。如gRPC使用HTTP2。不同的协议各有利弊。TCP更加高效，而HTTP在实际应用中更加的灵活。 

 **REST与RPC比较** 

`  都是网络交互的协议规范。通常用于多个微服务之间的通信协议。 ` 

![img](https://ss2.baidu.com/6ONYsjip0QIZ8tyhnq/it/u=3120375422,3070483665&fm=173&app=49&f=JPEG?w=640&h=166&s=0D2274324D664D2048F595CA0000C0B1)

***\*REST与RPC应用场景\****

**REST和RPC都常用于微服务架构中。** 

>  1、HTTP相对更规范，更标准，更通用，无论哪种语言都支持http协议。如果你是对外开放API，例如开放平台，外部的编程语言多种多样，你无法拒绝对每种语言的支持，现在开源中间件，基本最先支持的几个协议都包含RESTful。

> 2、 RPC 框架作为架构微服务化的基础组件，它能大大降低架构微服务化的成本，提高调用方与服务提供方的研发效率，屏蔽跨进程调用函数（服务）的各类复杂细节。让调用方感觉就像调用本地函数一样调用远端函数、让服务提供方感觉就像实现一个本地函数一样来实现服务。

**最后建议** 

REST调用及测试都很方便，RPC就显得有点繁琐，但是RPC的效率是毋庸置疑的，所以建议在==多系统之间的内部==调用采用RPC。==对外==提供的服务，Rest更加合适。

-------------------------

###  **谈谈RESTful规范** 

```python
Representational State Transfer "表现层状态转化"
restful其实就是一套'编写接口的协议'，协议规定如何编写以及如何设置返回值、状态码等信息。
restful: 给用户一个url，根据method不同在后端做不同的处理，比如：post 创建数据、get获取数据、put
和patch修改数据、delete删除数据。
（1）每一个URI代表一种资源；
（2）客户端和服务器之间，传递这种资源的某种表现层；
（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现"表现层状态转化"。
我们常用的状态码： 
200   请求成功 
301   永久重定向
302   临时重定向   
403   权限问题
404   找不到页面
500   服务器问题
```



###  **Web开发中，session和cookie的作用与区别。** 

**Cookie概念**

>  在浏览某些 网站 时,这些网站会把 一些数据存在 客户端 , 用于使用网站 等跟踪用户实现用户自定 义 功能. 

```python
#是否设置过期时间:
     如果不设置 过期时间,则表示这个 Cookie生命周期为浏览器会话期间 , 只要关闭浏览器,cookie就消失了.
 这个生命期为浏览会话期的cookie,就是'会话Cookie';
#存储:一般保存在内存,不在硬盘;
    如果设置了过期时间, 浏览器会把cookie保存在硬盘上,关闭再打开浏览器, 这些cookie 依然有效直到 超
 过的设置过期时间;
```

 **Session的概念  ** 

```python
'作用'：实现网页之间数据传递，是一个存储在服务器端的对象集合。
  "原理"：当用户请求一个Asp.net页面时，系统将自动创建一个Session;退出应用程序或关闭服务器
时，该Session撤销。系统在创建Session时将为其分配一个长长的字符串标识，以实现对Session进行管理与跟踪。
```

##### DJango,Falsk **cookie和session的区别：**

```python
#1.cookie:
    cookie是保存在浏览器端的键值对,可以用来做用户认证
#2.session：
  将用户的会话信息保存在服务端,key值是随机产生的自符串,value值时session的内容依赖于cookie将每个用户的随机字符串保存到用户浏览器上
#Django中session默认保存在数据库中：django_session表
#flask,  session默认将加密的数据写在用户的cookie中
```

 **Cookie和Session 的区别**

```python
    1、cookie数据存放在客户的浏览器上，session数据放在服务器上.简单的说，当你登录一个网站的时候，如果web服务器端使用的是session,那么所有的数据都保存在服务器上面，客户端每次请求服务器的时候会发送 当前会话的session_id，服务器根据当前session_id判断相应的用户数据标志，以确定用户是否登录，或具有某种权限。    
    "由于数据是存储在服务器 上面，所以你不能伪造"，但是如果你能够获取某个登录用户的session_id，用特殊的浏览器伪造该用户的请求也是能够成功的。
	session_id是服务器和客户端链接时候随机分配的，一般来说是不会有重复，但如果有大量的并发请求，也不是没有重复的可能性，我曾经就遇到过一次。
	登录某个网站，开始显示的 是自己的信息，等一段时间超时了，一刷新，居然显示了别人的信息。
    Session是由应用服务器维持的一个服务器端的存储空间，用户在连接服务器时，会由服务器生成一个唯一的SessionID,用该SessionID 为标识符来存取服务器端的Session存储空间。而SessionID这一数据则是保存到客户端，用Cookie保存的，用户提交页面时，会将这一SessionID提交到服务器端，来存取 Session数据。这一过程，是不用开发人员干预的。所以一旦客户端禁用Cookie，那么Session也会失 效。
    2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗考虑到安全应当使用session。
    3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用COOKIE。
    4、单个cookie保存的数据'不能超过4K'，很多浏览器都限制一个站点最多保存20个cookie。(Session对象没有对存储的数据量的限制，其中可以保存更为复杂的数据类型)
```

### **Web开发中有哪些技术手段防止SQL注入？**

```python
1.使用'预编译'绑定变量的SQL语句
2.严格加密处理用户的机密信息
3.不要随意开启生产环境中Webserver的错误显示
4.使用正则表达式过滤传入的参数
5.字符串过滤
6.检查是否包函非法字符
```

### **如何查看占用8080端口的是什么进程？**

```python
#windows查看端口占用
在windows命令行窗口下执行：
netstat -aon|findstr "8080"
#linux系统
先使用 netstat命令，再用 ps命令
执行命令： netstat -anp|grep 8080
输出结果： tcp 0 0 :::8080 :::* LISTEN 12006/java
执行命令： ps -ef | grep 12006
```

### **Django中FBV与CBV**

```python
#FBV（function base views） 就是在视图里使用函数处理请求。
#CBV（class base views） 就是在视图里使用类处理请求。
如果我们要写一个处理GET方法的view，用函数写的话是下面这样。
from django.http import HttpResponse
def my_view(request):
     if request.method == 'GET':
            return HttpResponse('OK')
如果用class-based view写的话，就是下面这样
from django.http import HttpResponse
from django.views import View
class MyView(View):
      def get(self, request):
            return HttpResponse('OK')
Django的url是将一个请求分配给可调用的函数的，而不是一个class。针对这个问题，class-based view提
供了一个as_view()静态方法（也就是类方法），
在url中，就这么写：
# urls.py
from django.conf.urls import url
from myapp.views import MyView
  
urlpatterns = [
     url(r'^index/$', MyView.as_view()),
]
```

##### **简述什么是FBV和CBV？**

```python
#FBV和CBV本质是一样的
#基于函数的视图叫做FBV，基于类的视图叫做CBV
在python中使用'CBV的优点'：
	1.提高了代码的复用性，可以使用面向对象的技术，比如Mixin（多继承）
	2.可以用不同的函数针对不同的HTTP方法处理，而不是通过很多if判断，提高代码可读性
```

##### **列举django中间件的5个方法？**

```python
#1.process_request : 请求进来时,权限认证
#2.process_view : 路由匹配之后,能够得到视图函数
#3.process_exception : 异常时执行
#4.process_template_responseprocess : 模板渲染时执行
#5.process_response : 请求有响应时执行
```

**django的request对象是在什么时候创建的？**

```python
class WSGIHandler(base.BaseHandler):
    request = self.request_class(environ)
#请求走到WSGIHandler类的时候，执行__cell__方法，将environ封装成了request
```

### 简述Django的orm**

```python
'ORM'，全拼Object-Relation Mapping，意为对象-关系映射
实现了数据模型与数据库的'解耦'，通过简单的配置就可以轻松更换数据库，而不需要修改代码只需要面
向对象编程,orm操作本质上会根据对接的数据库引擎，翻译成对应的sql语句,所有使用Django开发的项
目无需关心程序底层使用的是MySQL、Oracle、sqlite....，如果数据库迁移，只需要更换Django的数据
库引擎即可
```

### **简述Django下的(内建的)缓存机制。**

```
缓存是将一些常用的数据保存内存或者memcache中,在一定的时间内有人来访问这些数据时,则不再去
执行数据库及渲染等操作,而是直接从内存或memcache的缓存中去取得数据,然后返回给用户.django提
供了6中内存缓存机制，分别为：

开发调试缓存（为开发调试使用，实际上不使用任何操作）；
内存缓存（将缓存内容缓存到内存中）；
文件缓存（将缓存内容写到文件 ）；
数据库缓存（将缓存内容存到数据库）；
memcache缓存（包含两种模块，python-memcached或pylibmc.）。
以上缓存均提供了三种粒度的应用。
```











## Flask

##### 简述Flask上下文管理流程?

> a、简单来说，falsk上下文管理可以分为三个阶段：
> 　　1、'请求进来时'：将请求相关的数据放入上下文管理中
> 　　2、'在视图函数中'：要去上下文管理中取值
>        3、'请求响应'：要将上下文管理中的数据清除
> b、详细点来说：
> 　　1、'请求刚进来'：将request，session封装在RequestContext类中app，g封装在AppContext类中，并通过LocalStack RequestContext和 AppContext放入Local类中
> 　　2、'视图函数中'：通过localproxy--->偏函数--->localstack--->local取值
> 　　3、'请求响应时'：先执行save.session()再各自执行pop(),将local中的数据清除

------------------------------------------------
##### Flask中的g的作用？

> g是贯穿于一次请求的全局变量，当请求进来将g和current_app封装为一个AppContext类，再通过LocalStack将AppContext放入Local中，取值时通过偏函数在LocalStack、local中取值；响应时将local中的g数据删除：

------------------------------------------------






## TCP 协议/UDP协议

#### TCP

+ TCP是面向连接的通讯协议，通过三次握手建立连接，通讯时完成四次挥手
+ 优点：
  + TCP在数据传输时，有确认，窗口，重传，阻塞等控制机制，能保证数据的正确性，较为可靠

- 缺点：
  - TCP相对于UDP速度慢一点，要求系统资源较

##### **三次握手四次挥手**

> 三次握手：是指在建立一个TCP连接时，需要客户端和服务端总共发送三个包
>
> >  1.第一次握手：客户端发送一个TCP的SYN标志位1的包指明客户端打算连接服务端，并发送初始序号X 
>
> > 2.第二次握手：服务器发回确认包（ACK）应答，即SYN和ACK标志位都为1时，将 确认序号设置为X+1 
>
> > 3.第三次握手：客户端再次发送确认包（ACK）SYN标志位为0，ACK标志位为1，并且把服务器发来ACK的序号字段+1，放在确认字段中发送给服务端 

>四次挥手：TCP的连接拆除需要发送四个包，客户端和服务端均可主动发起挥手动作
>
>> 1.主动方发送Fin+Ack报文，并发送序号X，请求通信关闭
>
>> 2.被动方发送ACK报文，并置发送序号为Z，确认序号为X+1，答应你关闭通信
>
>>  3.被动方发送Fin+Ack报文，并置发送序号为Y，确认序号为X，也请求关闭通信
>
>> 4.主动方发送ack报文，并发送序号为X，确认序号为Y，也答应关闭通信

#### UDP

> UDP是面向无连接的通讯协议， 且不安全的协议，在通信过程中，它并不像TCP那样需要先建立一个连接，只要目的端口号和源端口号确定了， 就能直接发送信息报文，它只提供校验机制来保证报文的完整性，若校验失败，则直接丢报文，不做任何处理。 

+ 优点：
  + 传输速度快，操作简单，要求系统资源少，由于通讯不需要连接，可以实现广播发送
+ 缺点：
  + 由于UDP是无连接的，所有它并不知道接收端是否正确接收，也不重复发送，容易出现丢包现象,不可靠

##### 选择

TCP一般用于文件传输，邮件接发，远程登陆

UDP一般用于在线视频，网络电话





## [多进程]()。线程。协程

#### 进程

+ 进程 之间的通信由操作系统传递，导致通讯效率低，切换开销大
+ 密集CPU任务，需要充分利用多核CPU资源（大量并行计算）的时候
  - 缺陷：成本高，开销大

##### 进程之间的通信:

1. 管道：**` 速度慢，容量有限，只有父子进程能通讯`** 
2. FIFO：**` 任何进程间都能通讯，但速度慢`** 
3. 消息队列：**` 容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完的数据的问题`** 
4. 信号量：**` 不能传递复杂消息，只能用来同步`** 
5. 共享内存区：**` 能够很容易控制容量，速度快，但要保持同步`** 
   - 比如一个程序在写的时候，另一个程序要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间的通讯。不过没必要，线程间本来就已经共享了同一进程的一块内存

​	

#### 线程

- 线程分享进程的内存空间，通讯效率高，切换开销小。共享意味着竞争，导致数据不安全，可以引用“互斥锁”

- 而在cpython中，有GIL（全局解释器锁）：

  - 线程执行权限，进程中只有一个GIL

    - 好处：杜绝多个线程访问内存空间的安全问题

    - 坏处：不是真正的多线程，不能充分利用多核CPU的资源

  - 在I/O阻塞时，解释器会释放GIL

- 密集型I/O任务，使用多线程
  - 缺陷：同一时间切片只能运行一个线程，不能做到高并行，但可以做到==高并发==

#### 协程

- 在单线程上执行多个任务，用函数切换，开销极小。
  - genvent, monkey.patchall

- 多线程请求返回是无序的，而协程返回的数据是有序的
- 缺陷：单线程执行，处理密集CPU和本地磁盘I/O时，性能低。处理网络I/O性能高

## Docker

+ ###### 什么是Docker
  
  + 开源的应用容器引擎, 基于 [Go 语言](https://www.runoob.com/go/go-tutorial.html) 并遵从Apache2.0协议开源 
  + docker 重新定义了程序开发测试，交付和部署过程的开放平台。
  + docker可以保持开发，测试和生产环节高度一致
+ docker 利用了namespace 来做权限的控制和隔离， cgroups 进行资源的配置，通过 aufs 进一步提高文件系统的资源了利用率
+ 相对于VM，优势：
  + 启动速度快
  + 资源利用率高
  + 性能开销小

#### Docker

### FastDFS





### Django 开发中对数据库的优化：

1. 设计表时，尽量少使用外键，影响插入和删除性能
2. 使用缓存， 减少数据库的访问
3. 在orm框架设计表时，能用varchar，就别用text
4. 给搜索高频的字段属性，在定义时创建索引
5. 在模块标签里使用with标签可以缓存Qset的查询结果

### Django 提升性能（高并发）

+ ##### 后端提升性能指标：
  
  + 并发数
+ 响应时间
  
+ #### web网站性能的优化：
  
  + web前端性能优化
    + 1.减少 http 请求，减少数据库的访问量，比如使用雪碧图。 
    + 2.使用浏览器缓存，将一些常用的 css，js，logo 图标，这些静态资源缓存到本地浏览器，通过设
      置 http 头中的 cache-control 和 expires 的属性，可设定浏览器缓存，缓存时间可以自定义。
    +  3 对 html，css，javascript 文件进行压缩，减少网络的通信量。
  + 应用服务器--
+ 储存服务器--
  
+ #### 解决 -优化

  + 合理应用缓存，对常用的动态数据，比如首页做缓存，或者其他常用的数据，并设置过期时间，减少数据库压力，提升网站性能
  + 使用celery消息队列，将耗时的操作放队列，让worker去监听队列任务，实现异步操作，如发邮件，发短信
  + nginx部署项目，提升效率，增加并发量
  + 搭建服务器集群，将并发访问请求分散到多台服务器上处理
  + 最后就是运维工作人员的性能优化技术了

### 高并发

+ ##### 什么是高并发

  +  通过设计保证系统能够同时并行处理很多请求 
    +  高并发相关常用的一些指标：
       +  响应时间（Response Time）
       +  吞吐量（Throughput）
       +  每秒查询率QPS（Query Per Second）
       +  并发用户数等 

+ ##### 如何提升系统的并发能力

  +  垂直扩展（Scale Up） 
    +  增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
    +   提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；  
  +  水平扩展（Scale Out） 
    +  只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的 

+ ##### 解决方式：

  + HTML页面静态化

  + 2.图片服务器分离（我使用的是fastdfs轻量级的分布式文件存储系统）

  + 3.使用缓存（缓存存在于内存中读取快我的项目中使用redis作为缓存的数据库，redis是内存型数据作为存储缓存的数据库挺适合）

  + 4.数据库集群、库表散列

  + 5.使用负载均衡的方法（简单的配置可以用nginx来配置负载均衡，只需要设置 如下代码，即可实现简单的负载均衡

    ```
      upstream djangoserver {  
                  server      192.168.72.49:8080;  
                 server 	    192.168.72.49:8081;  
              } 
    ```

  + 6.镜像
  + 7.最新：CDN加速技术（此技术还在了解阶段，可自行去网上查找相关的资料）

## Mysql， MongoDB， Redis

` ‘重要数据：mysql，一般数据：mongodb，临时数据：
memcache’`

#### MongoDB

+  MongoDB 是一个面向文档的数据库系统。以 BSON 结构（二进制）进行存储，对海量数据存储有着很明显的优势。 

```
Monogo 使用C++编写，不支持SQL
BSON 是一种类似于JSON的二进制序列化文档，支持嵌套对象和数组
```

##### 优点

1. **性能优越:快速**！

> 在适量级的内存的 MongoDB ==的性能是非常迅速的==，它将热数据存储在物理内存中，使得热数据的读写变得十分快

2. **高扩展**:

> 第三方支持丰富(这是与其他的 No SQL 相比，MongoDB 也具有的优势)

3. 自身的 **Failover 机制**！ 

   > 故障转移机制： 自动故障切换特性来提供的高可用功能，当主节点成员不可用时从节点成员会自动变成主节点来继续对外提供服务

4. **弱一致性**（最终一致），更能保证用户的访问速度 

5. ** 用于对象及 JSON 数据的存储**

> mongo 的 BSON 数据格 式非常适合文档格式化的存储及查询

6. **内置 GridFS,支持大容量的存储** 

> 高效存储二进制大对象 (比如照片和视频

7. **全索引支持** 

   > 扩展到内部对象和内嵌数组

8. **内置 Sharding** 

>  MongoDB 的 sharding 的特色就是自动化。具体体现为可以动态扩容、自动平衡数据、以及透明的使用接口。可以从一个普通的 replica set，或者单个实例平滑升级，可以动态增加删除节点，响应数据快速增长。可以自动在节点间平衡数据量，避免负载集中在少数节点，而在这期间不影响数据库读写访问。对客户端，可以使用完全相同的驱动，大部分功能可用，基本不需要更改任何代码。 

##### 缺点：

+   MongoDB 不支持事务操作(最主要的缺点)
+   MongoDB 占用空间过大
+   MongoDB 没有如 MySQL 那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方



#### Redis

> 它就是一个不折不扣的内存数据库。

##### Redis 事务

> Redis的事务是一组命令的集合,一个事务的所有命令要么执行,要么都不执行

` multi:开启事务`

` exec:执行事务` 

redis不支持事务的回滚

##### Redis持久化存储

+ 持久化方式:

  > Redis 所有数据都是放在内存中的，持久化是使用 RDB 方式或者 aof 方式。 

- **RDB快照(默认)** 

  ```
  原理：
  	Redis借助了fork命令的copy on write机制。在生成快照试时，将当前进程fork出一个子进程，然后在子进程中循环所有的数据，将数据写成RDB文件，使用redis的save命令调用这个过程
  级别：
  	save 900 1
  	save 300 10
  	save 60 10000
  优点：
  	1.RDB是保存某个时间点的数据集，适用于数据集的备份
  	2.RDB是一个单一文件，方便传输到远端数据中心，适用于灾难回复
  	3.RDB方式可以最大化redis的性能
  缺点：
  	一旦数据库出现问题，RDB文件中保存的数据并不是全新的额，从上次保存到Redis停机这段时间的数据全部丢失
  ```

- **AOF** 

  ```
  原理：
  	对每条写入命令作为日志，以aooend-only模式写入一个日志文件，在redis重启时，可以通过AOF写入的指令来重构整个数据集
  级别：
  	30s 写入一次
  	1s 写入一次
  	每次写操作就写入一次
  优点：
  	1.AOF可以更好的保护数据不丢失，一般每隔1秒执行一次fsync操作，如果redis挂掉，最多丢失1秒的数据
  	2.保存的AOF日志格式文件是按照redis协议的格式保存，易于读取
  缺点：
  	1.速度没有RDB快
  	2.在一个高并发的系统中，命令日志是一个非常庞大的数据，管理维护成本高，恢复重建时间会非常长
  	
  ```


- **` 选择` ** 

  RDB + AOF：综合使用两种持久化方式，用AOF保证数据不丢失，作为恢复数据的第一选择；用RDB来做冷备份，在AOF文件丢失或不可用的时候，用RDB进行快速的数据恢复

##### **优点**

```python
1 读写性能优异 
2 支持数据持久化，支持 'AOF' 和 'RDB' 两种持久化方式 
3 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。
4 数据结构丰富：除了支持 string 类型的 value 外还支持 string、hash、set、sortedset、list 等数据结构。
```

##### **缺点**

```python
1 Redis' 不具备自动容错和恢复功能'，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。 
2 '主机宕机'，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，'降低了系统的可用性'。 
3 Redis的'主从复制采用全量复制'，复制过程中主机会'fork '出一个子进程对内存做一份快照，并将子进程的内存快照保存 为文件发送给从机，这一过程需要确保主机有足够多的空余内 存。若快照文件较大，对集群的服务能力会产生较大的影响， 而且复制过程是在从机新加入集群或者从机和主机网络断开重 连时都会进行，也就是网络波动都会造成主机和从机间的一次 全量的数据复制，这对实际的系统运营造成了不小的'麻烦'。 
4 'Redis 较难支持在线扩容'，在集群容量达到上限时在线 扩容会变得很复杂。为避免这一问题，运维人员在系统上线时 必须确保有足够的空间，这对资源造成了很大的浪费。
```

### Redis/Mongodb

```python
1. MongoDB 和 Redis 都是 NoSQL，采用结构型数据存储。
2. 二者在使用场景中，存在一定的区别，这也主要由于二者在内存 映射的处理过程，持久化的处理方法不同。
3. MongoDB 建议'集群 '部署，更多的考虑到集群方案，
4. Redis 更偏重于进程顺序写入， 虽然支持集群，也'仅限'于'主-从模式'
```

#### MongoDB 和 Redis 的区别：

+ ###### 集群

  + MongoDB 集群技术比较成熟，Redis从3.0开始支持集群。 

+ ###### 内存管理机制

  + Redis 数据全部存在内存，定期写入磁盘，当内存不够时，可以选择指定的 LRU 算法删除数据。
  + MongoDB 数据存在内存，由 linux系统 mmap 实现，当内存不够时，只将热点数据放入内存，其他数据存在磁盘。


  + ###### 支持的数据结构

    + Redis 支持的数据结构丰富，包括hash、set、list等。
    + MongoDB 数据结构比较单一（K-V），但是支持丰富的数据表达，索引，最类似关系型数据库，支持的查询语言非常丰富。


  + ###### 不适用的场景

    Ø  需要使用复杂sql的操作

     Ø  事务性系统 



### MySQL

##### MySQL的引擎

+  InnoDB和MyISAM是MySQL的存储引擎 
+  区别 

```tex
1.InnoDB支持事务,MyISAM不支持,对于InnoDB每一条SQL语言都默认封装成事务,自动提交,这样会影响速度,所以最好把多条SQL语言放在begin和commit之间,组成一个事务；
2.InnoDB支持外键,而MyISAM不支持.对一个包含外键的InnoDB表转为MYISAM会失败；
3.InnoDB是聚集索引,数据文件是和索引绑在一起的,必须要有主键,通过主键索引效率很高.但是辅助索引需要两次查询,先查询到主键,然后再通过主键查询到数据.因此,主键不应该过大,因为主键太大,其他索引也都会很大.而MyISAM是非聚集索引,数据文件是分离的,索引保存的是数据文件的指针.主键索引和辅助索引是独立的.
4.InnoDB不保存表的具体行数,执行select count(*) from table时需要全表扫描.而MyISAM用一个变量保存了整个表的行数,执行上述语句时只需要读出该变量即可,速度很快；
5.Innodb不支持全文索引,而MyISAM支持全文索引,查询效率上MyISAM要高；
6.MySQL5.6版本InnoDB已支持全文索引
```

- 选择

  ```tex
  1.是否要支持事务,如果要请选择innodb,如果不需要可以考虑MyISAM；
  2.如果表中绝大多数都只是读查询,可以考虑MyISAM,如果既有读写也挺频繁,请使用InnoDB.
  3.系统奔溃后,MyISAM恢复起来更困难,能否接受；
  4.MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM),说明其优势是有目共睹的,如果你不知道用什么,那就用InnoDB,至少不会差.
  ```

- 总结

  - 读操作多用MyISAM
  - 写操作多用InnoDB

##### 复制集和分布式

- 复制集：搭建主从数据库
  - 目的：
    - 数据库的数据相同，起到备份的作用
    - 高可用——HA ： 提高稳定性
    - 数据库的读写分离：**写操作涉及到锁的问题，不管是行锁还是表锁还是块锁，都是比较降低系统执行效率的事情。我们这样的分离是把写操作集中在一个节点上，而读操作其他的N个节点上进行，从另一个方面有效的提高了读的效率，保证了系统的高可用性**。
- 分布式：数据库的数据不同， 每部分的数据共同组成完整的数据集合
  - 每个节点被称为一个节点
  - 高吞吐（提高查询效率）
- 复制集和分布式可单独使用，也可组合使用，组合使用时，分布式的每个分片都是主，复制集的是从

##### MySQL主从复制原理

- master将改变记录到二进制日志（binary log)中，
- slave将master的binary log events拷贝到他的中继日志（relay log)
- SQL线程从中继日志中读取事件，更新slave的数据



##### MySQL数据库事务

###### **事务具有ACID的特性：**

> 1. 原子性  2. 一致性  3. 隔离性   4. 持久性

1. **原子性(atomicity)**:事务中的所有操作是不可分割的，要么全部提交成功，要么全部失败回滚。

2. **一致性(consistency)**:数据库总是从一个一致性状态转换到另一个一致性状态。

3. **隔离性(isolation)** :一个事务所做的修改在提交之前对其它事务是不可见的。

4. **持久性(durability)**:一旦事务提交，其所做的修改便会永久保存在数据库中。

###### 事务隔离的四个级别

- **Read Uncommitted:** ` 读取未提交, 隔离级别最低的一个事务级别.一个事务会读取到另一个事务更改后未提交的数据，当事务回滚后，这个事务读到的数据就是脏数据，称为脏读` 
- **Read Committed**:`  读取已提交：该隔离级别下，一个事务会遇到不可重复读的问题。 `

```
不可重复读：A事务内，需要多次读取同一个数据，同时，B事务修改了该数据，那么，A事务多次读取的数据可能不一致。虽然解决了脏读的问题，未提交之前数据不变，但是当A事务在不知道B事务的存在下，有可能两次读的数据不同，所以正确的就是只读一次，不要多次读取。
```

- **Repeatable Read:** `  可重复读：该隔离级别下，不管是否提交，一个事务不会读到另一个事务的更改，每次都是读取的原始数。但是会出现幻读问题 ` 
- **Serializable:** `  串行执行事务：最高级别的隔离，所有事务依次执行，避免了脏读和可重复读，但是降低了效率和程序性能 `

##### 读写分离对事务的影响

- 对于写操作，因为事务是单机的（不能跨服务器），所以开启事务和提交或回滚分散到不同服务器就会失效
- 对于包含读写操作时：与事务的隔离级别相关，可重复度有影响；其他没有影响。



##### 分布式ID--唯一的id

- Redis的inrc和inrcby
- 雪花算法



##### 索引的底层原理

- 建立底层平衡的搜索二叉树（大多数B树）左儿子始终小于老子；右儿子始终大于老子。

- 索引提高了查询速度，但是会影响增删改的速度：

  ```
  当新增数据影响到二叉树的平衡时，二叉树需要重新调整结构，这个过程性能消耗大，所以速度慢
  ```

  



##### MySQL性能优化方法

- 按照三范式设计表
- 设计表时，考虑到有些字段为了方便查询，而采用空间换取时间的方法，适当增加冗余字段（反范式设计）
- 建立索引
- sql语句优化
  - 使用索引遵循最左原则
  - 不要 select * , 只查询要查询的字段
  - 尽量不使用联合查询
  - 普通查询 > 联合查询 > 子查询
  - SQL语句尽量大写
  - 选择恰当的数据类型，如整型的选择； VARCHAR
  - 对于强调快速读取的操作，可以考虑使用MyISAM数据库引擎；
  - 对于模糊 like 查询 将导致全表扫描，应避免使用
- 内存型数据库：mysql + redis
- 配置主从，读写分离









## Nginx和uWSGI

+ nginx
  + 它是一个开源的高性能的HTTP服务器和反向代理
    1. 作为web服务器，他处理静态和索引文件的效果非常高
    2. 最大支持5W个并发连接，但占用很少的内存空间
    3. 稳定性高，配置简洁
       1. 强大的反向代理和负载均衡功能，平衡集群各个服务器负载压力的应用
  + uWSGI -- web服务器
    + 实现WSGI，uwsgi，http等协议
    + WSGI 是一种通信协议。
      + WSGI 是一种Web 服务器网关接口。
      + 它是一 个Web 服务器（如 nginx，uWSGI 等服务器）与 web 应用（如用 Flask 框架写的程序）通信的一种 规范。
    + uwsgi是一种线路协议而不是通信协议，在此常用于在 uWSGI 服务器与其他网络服务器的数据通信
    + uWSGI 是实现了 uwsgi 和WSGI 两种协议的Web 服务器。

## HTTP和HTTPS

+ ##### 主要区别：

  + HTTPS需要ca证书，需要一定的费用
  + HTTP是超文本传输协议，是无状态的；HTTPS是HTTP，SSL协议构建的可进行加密传输，身份认证的网络协议，比http更安全
  + 使用的端口不同，HTTP使用80，HTTPS使用443

+ ##### ***为什么大多数公司选择http而不选择https：***

  1. HTTPS在“握手阶段”比较耗时，而且连接缓存也不如HTTP高效，所以，HTTPS没HTTP速度快
  2. SSL证数（CA证书）是需要花钱的，并且需要每年投入，对很多小公司和个人开发者挡住了
  3. HTTPS对服务器资源占用率高， 也就是需要在硬件投入上花费更多。

## 面向过程和面向对象的区别

+  面向对象就是高度实物抽象化
+ 面向过程就是自顶向下的编程！ 

#### 面向过程:

+ 优点：
  + 性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;
  + 比如单片机、嵌入式开发、 Linux/Unix等一般采用面向过程开发，性能是最重要的因素。 
+ 缺点：没有面向对象易维护、易复用、易扩展
  

#### 面向对象:

+ ##### 三特性

  + 继承
  + 多态
  + 封装

+ ##### 优点:

  +  易维护、易复用、易扩展，
  + 由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护 

+ 缺点：

  + 性能比面向过程低 


## Socket

#### socket与TCP/IP的关系

- socket是应用层和传输层之间的一个抽象层
- 它把TCP/IP层的复杂操作抽象为几个简单的接口供应用层调用，从而实现进程在网络之间的通信

#### 什么是socket

`  套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。 `



-  Socket的英文原义是“插座” 。 通常也称作”套接字”，主要用于解决==网络进程间通信。==   

-  两个进程如果需要进行通讯最基本的一个前提能能够唯一的标示一个进程。 

  

- 通信
  -  ==本地进程间通信== （PIPE、FIFO、message queue、semaphore、shared memary）可以通过进程ＩＤ唯一标识一个进程。 
  - ==网络进程通信：==` IP地址+协议+端口号 `唯一标识网络中的一个进程

#### socket（）函数

1. 创建套接字

   ```python
   socket.socket(socket.AF_INET, socket.SOCK_STREAM)
   ```

2. bind()函数： 绑定端口

3. listen（128）：监听，等待客户端连接并设置最大连接数（128）

4. accept（）：建立客户端连接

5. send（）/recv（）：交互

6. close（）：关闭连接

## Celery底层原理

#### 架构

1. **消息中间件（Broker）** 
   - 是任务调度队列，是一个独立的服务器
   - 是一个生产者消费者模式
     - 生产者把任务放进队列中
     - 消费者从任务队列取出任务执行
       - 任务执行可以是按照顺序也可以是按照计划时间进行
       - 但Broker本身**不提供队列服务**，所以集成第三方队列：推荐使用RatbbitMQ 或 Redis
2. **任务执行单元（worker）** 
   - 实时监控消息队列，获取队中的调度任务并执行
3. **任务执行结果储存（task result story）** 
   - 由于任务和主程序分开，若要获取结果，必须通过中间键储存。也可以使用RatbbitMQ,Redis
   - 若不需要保存结果，可不配置





## Elastic Search

##### 熟么是ElasticSearch：

> ElasticSreach 是基于Apache Lucene（TM）的开源搜索引擎

##### Lucene是什么:

 `  无论在开源还是专有领域，Lucene 可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库，并通过简单的 RESTful API 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。 ` 

 **Elasticsearch 不仅仅是 Lucene 和全文搜索**，我们还能这样去描述它： 

> > - 分布式的实时文件存储，每个字段都被索引并可被搜索
> > - 分布式的实时分析搜索引擎
> > - 可以扩展到上百台服务器，处理 PB 级结构化或非结构化数据

[基础内容太多，自行查找]( https://blog.csdn.net/feiyingwang/article/details/95626694#_10 )



## Haystack

## 

## JWT



## WebSocket

>  Socket 是传输控制层协议，WebSocket 是应用层协议。 

#####  websocket 跟 socket 的区别 

> 软件通信有七层结构，下三层结构偏向与数据通信，上三层更偏向于数据处理，中间的传输层则是连接上三层与下三层之间的桥梁，每一层都做不同的工作，上层协议依赖与下层协议。基于这个通信结构的概念。
>
>  **Socket 其实并不是一个协议，是应用层与 TCP/IP 协议族通信的中间软件抽象层，它是一组接口。** 当两台主机通信时，让 Socket 去组织数据，以符合指定的协议。TCP 连接则更依靠于底层的 IP 协议，IP 协议的连接则依赖于链路层等更低层次。
>
> WebSocket 则是一个典型的应用层协议。



## 什么是数据结构和算法

#### 数据结构

>  数据结构是数据对象，以及存在于该对象的实例合组成实例的数据元素之间的各种联系。这些联系可以通过定义相关的函数来给出。 

#### 算法 

>  算法是解决问题步骤的有限集合，通常用某一种计算机语言进行伪码描述。通常用时间复杂度和空间复杂度来衡量算法的优劣。 



## [树]( https://mp.weixin.qq.com/s?__biz=Mzg2NzA4MTkxNQ==&mid=2247486101&idx=1&sn=980f6dfb7643a9ff4f5a661d4a496046&chksm=ce404141f937c85750232523583435e97f3965a3761fa327e5d79e2b720dfced1a1dfc731d3b&token=1321503479&lang=zh_CN#rd ) 

##### 为什么用B树而不用二叉查找树

> 减少对数据库（ **磁盘的寻址加载次数** ）的访问次数

##### 为什么有了平衡树还要红黑树

> 平衡树在读写频繁的时候容易被打破平衡，需要频繁的调整；而红黑树不会
>
> > 但在查找方面，平衡树比红黑树快
>
> 所以，红黑树是不严格的平衡树（也可以说是一个折中的方案）



